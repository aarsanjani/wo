{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Complete Project Workflow in Amazon SageMaker\n",
    "### Model Deployment\n",
    "    \n",
    "1. [Local Mode endpoint](#LocalModeEndpoint)\n",
    "2. [SageMaker hosted endpoint](#SageMakerHostedEndpoint)\n",
    "3. [Multi-Model endpoints](#MultiModelEndpoints)\n",
    "4. [Production Variants with Model Monitor](#ProductionVariants)\n",
    "5. [Invoking SageMaker endpoints](#InvokingSageMakerEndpoints)\n",
    "6. [Clean up resources](#CleanUp)\n",
    "\n",
    "## Local Mode endpoint <a class=\"anchor\" id=\"LocalModeEndpoint\">\n",
    "\n",
    "While Amazon SageMakerâ€™s Local Mode training is very useful to make sure your training code is working before moving on to full scale training, it also would be useful to have a convenient way to test your model locally before incurring the time and expense of deploying it to production. One possibility is to fetch the XGBoost artifact or a model checkpoint saved in Amazon S3, and load it in your notebook for testing. However, an even easier way to do this is to use the SageMaker Python SDK to do this work for you by setting up a Local Mode endpoint.\n",
    "\n",
    "More specifically, the Estimator object from the Local Mode training job can be used to deploy a model locally. With one exception, this code is the same as the code you would use to deploy to production. In particular, all you need to do is invoke the local Estimator's deploy method, and similarly to Local Mode training, specify the instance type as either `local_gpu` or `local` depending on whether your notebook is on a GPU instance or CPU instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the variables stored from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameter_store import ParameterStore\n",
    "import sagemaker\n",
    "from sagemaker.session import s3_input\n",
    "import numpy as np\n",
    "\n",
    "ps = ParameterStore()\n",
    "parameters = ps.read()\n",
    "\n",
    "bucket = parameters['bucket']\n",
    "s3_prefix = parameters['s3_prefix']\n",
    "raw_s3 = parameters['raw_s3']\n",
    "train_dir = parameters['train_dir']\n",
    "test_dir = parameters['test_dir']\n",
    "train_dir_csv = parameters['train_dir_csv']\n",
    "test_dir_csv = parameters['test_dir_csv']\n",
    "local_model_data = parameters['local_model_data']\n",
    "remote_model_data = parameters['remote_model_data']\n",
    "training_job_name = parameters['training_job_name']\n",
    "tuning_job_name = parameters['tuning_job_name']\n",
    "s3_input_train_uri = parameters['s3_input_train_uri']\n",
    "s3_input_test_uri = parameters['s3_input_test_uri']\n",
    "role = parameters['role']\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "s3_input_train = s3_input(s3_input_train_uri, content_type='csv')\n",
    "s3_input_test = s3_input(s3_input_test_uri, content_type='csv')\n",
    "inputs = {'train': s3_input_train, 'test': s3_input_test}\n",
    "\n",
    "x_test = np.load('./data/test/x_test.npy')\n",
    "y_test = np.load('./data/test/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following single line of code deploys the model locally in the SageMaker XGBoost container using the model artifacts from our local training job:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "local_model = XGBoostModel(entry_point='train_deploy.py', model_data=local_model_data, role=role, framework_version='1.0-1')\n",
    "local_predictor = local_model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the Local Mode endpoint, simply invoke the Predictor's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "local_predictor.content_type = 'text/csv'\n",
    "local_predictor.accept = 'text/csv'\n",
    "local_predictor.serializer = csv_serializer\n",
    "local_predictor.deserializer = json_deserializer\n",
    "\n",
    "local_predictor.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the predictions can be compared against the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_results = [local_predictor.predict(x_test[i]) for i in range(0, 10)]\n",
    "print(f'predictions: \\t {local_results}')\n",
    "print(f'target values: \\t {y_test[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only trained the model for a few rounds, but the predictions so far should at least appear reasonably within the ballpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having the SageMaker TensorFlow Serving container indefinitely running locally, simply gracefully shut it down by calling the `delete_endpoint` method of the Predictor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker hosted endpoint <a class=\"anchor\" id=\"SageMakerHostedEndpoint\">\n",
    "\n",
    "Assuming the best model from the tuning job is better than the model produced by the individual Hosted Training job above, we could now easily deploy that model to production.  A convenient option is to use a SageMaker hosted endpoint, which serves real time predictions from the trained model (Batch Transform jobs also are available for asynchronous, offline predictions on large datasets). The endpoint will retrieve the XGBoost saved model created during training and deploy it within a SageMaker XGBoost Serving container. This all can be accomplished with one line of code.  \n",
    "\n",
    "More specifically, by calling the `deploy` method of the HyperparameterTuner object we instantiated above, we can directly deploy the best model from the tuning job to a SageMaker hosted endpoint.  It will take several minutes longer to deploy the model to the hosted endpoint compared to the Local Mode endpoint, which is more useful for fast prototyping of inference code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "container = get_image_uri(sess.boto_region_name, 'xgboost')\n",
    "train_instance_type = 'ml.m4.xlarge'\n",
    "hyperparameters = {'num_round': 8}\n",
    "model = Estimator.attach(training_job_name)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium', endpoint_name='xgboost-housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the hosted endpoint, simply invoke the Predictor's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type = 'text/csv'\n",
    "predictor.accept = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "predictor.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_results = [predictor.predict(x_test[i]) for i in range(0, 10)]\n",
    "print(f'local predictions: \\t {local_results}')\n",
    "print(f'hosted predictions: \\t {hosted_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker hosted endpoint with autotuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter\n",
    "\n",
    "# Parameters from last notebook\n",
    "hyperparameter_ranges = {\n",
    "  'num_round': IntegerParameter(2, 10)\n",
    "}\n",
    "\n",
    "tuner_parameters = {'estimator':model,\n",
    "                    'objective_metric_name':'validation:aucpr',\n",
    "                    'hyperparameter_ranges':hyperparameter_ranges,\n",
    "                    #'metric_definitions':metric_definitions,\n",
    "                    'max_jobs':4,\n",
    "                    'max_parallel_jobs':2}\n",
    "tuner_parameters['estimator'] = model\n",
    "\n",
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "tuner = tuner.attach(tuning_job_name)\n",
    "tuning_predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.t2.medium',\n",
    "                                endpoint_name='xgboost-housing-auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_predictor.content_type = 'text/csv'\n",
    "tuning_predictor.accept = 'text/csv'\n",
    "tuning_predictor.serializer = csv_serializer\n",
    "tuning_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_results = [tuning_predictor.predict(x_test[i]) for i in range(0, 10)]\n",
    "print(f'local predictions: \\t {local_results}')\n",
    "print(f'tuner predictions: \\t {hosted_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking SageMaker Endpoints <a class=\"anchor\" id=\"InvokingSageMakerEndpoints\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restore the endpoint names we created from our parameters file just in case you decided to shut down the kernel or notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code so far, we've seen examples of training a model, deploying it as an endpoint, then using that deployed model object to do predictions. But what if we want to call an existing SageMaker endpoint? Well, there are a couple ways to do this. The first is with SageMaker's Python SDK and the second with boto3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling an endpoint with SageMaker's Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "predictor = RealTimePredictor(endpoint='xgboost-housing',\n",
    "                              sagemaker_session=sess,\n",
    "                              serializer=csv_serializer,\n",
    "                              deserializer=json_deserializer)\n",
    "\n",
    "predictor.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or call an endpoint using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "# Create a CSV string from the numpy array\n",
    "payload = ', '.join([str(each) for each in x_test[0]])\n",
    "prediction = sm_runtime.invoke_endpoint(EndpointName='xgboost-housing',\n",
    "                                        ContentType='text/csv',\n",
    "                                        Body=payload)\n",
    "prediction = json.loads(prediction['Body'].read())\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up <a class=\"anchor\" id=\"CleanUp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid billing charges from stray resources, you can delete the prediction endpoint to release its associated instance(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "tuning_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
